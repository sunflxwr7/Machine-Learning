{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzA9SRQcT-Hp",
        "outputId": "a2a8d343-642b-4868-9172-e3a3bb50a9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Fashion-MNIST dataset...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 48ms/step - accuracy: 0.7527 - loss: 0.6869 - val_accuracy: 0.8700 - val_loss: 0.3632\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 48ms/step - accuracy: 0.8790 - loss: 0.3349 - val_accuracy: 0.8880 - val_loss: 0.3106\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 50ms/step - accuracy: 0.8950 - loss: 0.2868 - val_accuracy: 0.8989 - val_loss: 0.2822\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 47ms/step - accuracy: 0.9104 - loss: 0.2422 - val_accuracy: 0.9010 - val_loss: 0.2707\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 49ms/step - accuracy: 0.9183 - loss: 0.2222 - val_accuracy: 0.9044 - val_loss: 0.2619\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 47ms/step - accuracy: 0.9287 - loss: 0.1964 - val_accuracy: 0.9098 - val_loss: 0.2531\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 47ms/step - accuracy: 0.9359 - loss: 0.1760 - val_accuracy: 0.9074 - val_loss: 0.2559\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 47ms/step - accuracy: 0.9425 - loss: 0.1557 - val_accuracy: 0.9071 - val_loss: 0.2641\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 48ms/step - accuracy: 0.9482 - loss: 0.1412 - val_accuracy: 0.9119 - val_loss: 0.2626\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 50ms/step - accuracy: 0.9545 - loss: 0.1219 - val_accuracy: 0.9125 - val_loss: 0.2621\n",
            "Test Accuracy on Fashion-MNIST: 0.9125\n",
            "Training Time on Fashion-MNIST: 784.08 seconds\n",
            "\n",
            "Training on MNIST dataset...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 49ms/step - accuracy: 0.8977 - loss: 0.3417 - val_accuracy: 0.9791 - val_loss: 0.0630\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 47ms/step - accuracy: 0.9847 - loss: 0.0500 - val_accuracy: 0.9828 - val_loss: 0.0504\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9891 - loss: 0.0353 - val_accuracy: 0.9884 - val_loss: 0.0357\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 47ms/step - accuracy: 0.9915 - loss: 0.0247 - val_accuracy: 0.9909 - val_loss: 0.0287\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 48ms/step - accuracy: 0.9950 - loss: 0.0159 - val_accuracy: 0.9882 - val_loss: 0.0359\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 47ms/step - accuracy: 0.9959 - loss: 0.0130 - val_accuracy: 0.9910 - val_loss: 0.0370\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 47ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.9901 - val_loss: 0.0362\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 47ms/step - accuracy: 0.9975 - loss: 0.0077 - val_accuracy: 0.9907 - val_loss: 0.0300\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 47ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9907 - val_loss: 0.0362\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 48ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9900 - val_loss: 0.0391\n",
            "Test Accuracy on MNIST: 0.9900\n",
            "Training Time on MNIST: 710.50 seconds\n",
            "\n",
            "\n",
            "Comparison of CNN Performance:\n",
            "Dataset        Test Accuracy  Training Time (s)\n",
            "---------------------------------------------\n",
            "Fashion-MNIST  0.9125         784.08         \n",
            "MNIST          0.9900         710.50         \n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Fashion-MNIST vs. MNIST Performance Comparison\n",
        "\n",
        "Objective:\n",
        "Compare the performance of a CNN model on the Fashion-MNIST dataset versus the MNIST digits dataset.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Function to load, preprocess, and train the model\n",
        "def train_and_evaluate(dataset, dataset_name):\n",
        "    print(f\"Training on {dataset_name} dataset...\")\n",
        "\n",
        "    # Load Dataset\n",
        "    (X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
        "\n",
        "    # Normalize Images (Scale to 0-1 range)\n",
        "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "    # Reshape Data for CNN Input (Adding channel dimension)\n",
        "    X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "    X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # Convert Labels to One-Hot Encoding\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "\n",
        "    # Define CNN Model\n",
        "    cnn = Sequential([\n",
        "        Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2,2)),\n",
        "        Flatten(),\n",
        "        Dense(units=128, activation='relu'),\n",
        "        Dense(units=10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile Model\n",
        "    cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train Model and Measure Time\n",
        "    start_time = time.time()\n",
        "    cnn.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64, verbose=1)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate Model\n",
        "    test_loss, test_acc = cnn.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    # Print Results\n",
        "    print(f\"Test Accuracy on {dataset_name}: {test_acc:.4f}\")\n",
        "    print(f\"Training Time on {dataset_name}: {end_time - start_time:.2f} seconds\\n\")\n",
        "\n",
        "    return test_acc, end_time - start_time\n",
        "\n",
        "# Train and Evaluate on Fashion-MNIST and MNIST\n",
        "test_acc_fashion, train_time_fashion = train_and_evaluate(fashion_mnist, \"Fashion-MNIST\")\n",
        "test_acc_mnist, train_time_mnist = train_and_evaluate(mnist, \"MNIST\")\n",
        "\n",
        "# Step 11: Compare Results\n",
        "print(\"\\nComparison of CNN Performance:\")\n",
        "print(f\"{'Dataset':<15}{'Test Accuracy':<15}{'Training Time (s)':<15}\")\n",
        "print(f\"{'-'*45}\")\n",
        "print(f\"{'Fashion-MNIST':<15}{test_acc_fashion:<15.4f}{train_time_fashion:<15.2f}\")\n",
        "print(f\"{'MNIST':<15}{test_acc_mnist:<15.4f}{train_time_mnist:<15.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercise 16.4: Modifying ConvNet Layers\n",
        "\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the Fashion-MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values (scale between 0 and 1)\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "# Reshape data for CNN input (28x28 images with 1 channel)\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define CNN model WITHOUT the first Dense layer\n",
        "cnn_no_dense = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Flatten(),\n",
        "    Dense(units=10, activation='softmax')  # Directly to output layer\n",
        "])\n",
        "\n",
        "# Compile and Train\n",
        "cnn_no_dense.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "start_time_no_dense = time.time()\n",
        "cnn_no_dense.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)\n",
        "end_time_no_dense = time.time()\n",
        "\n",
        "test_loss, test_acc_no_dense = cnn_no_dense.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy without First Dense Layer: {test_acc_no_dense:.4f}\")\n",
        "print(f\"Training Time without First Dense Layer: {end_time_no_dense - start_time_no_dense:.2f} seconds\")\n",
        "\n",
        "# Define CNN model WITH additional Dense(4096) layer\n",
        "cnn_4096 = Sequential([\n",
        "    Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2,2)),\n",
        "    Flatten(),\n",
        "    Dense(units=4096, activation='relu'),  # Added large Dense layer\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and Train\n",
        "cnn_4096.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "start_time_4096 = time.time()\n",
        "cnn_4096.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=64)\n",
        "end_time_4096 = time.time()\n",
        "\n",
        "test_loss, test_acc_4096 = cnn_4096.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy with Dense(4096): {test_acc_4096:.4f}\")\n",
        "print(f\"Training Time with Dense(4096): {end_time_4096 - start_time_4096:.2f} seconds\")\n",
        "\n",
        "# Summary of CNN Model Modifications\n",
        "print(\"\\nSummary of CNN Model Modifications:\")\n",
        "print(f\"{'Model':<30}{'Test Accuracy':<15}{'Training Time (s)':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Original CNN (Fashion-MNIST)':<30}{'91.39%':<15}{'787.45':<15}\")\n",
        "print(f\"{'CNN Without First Dense':<30}{test_acc_no_dense:<15.4f}{end_time_no_dense - start_time_no_dense:.2f}\")\n",
        "print(f\"{'CNN with Dense(4096)':<30}{test_acc_4096:<15.4f}{end_time_4096 - start_time_4096:.2f}\")\n",
        "\n",
        "# Observations:\n",
        "print(\"\\n Observations:\")\n",
        "print(\"- Taking out the first Dense layer makes training faster but lowers accuracy.\")\n",
        "print(\"- Adding a Dense(4096) layer improves accuracy a little but makes training slower.\")\n",
        "print(\"- If your computer is slow, using a smaller Dense layer (512 or 1024 neurons) is a better choice.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWCrHRe6awDH",
        "outputId": "a6a2bc62-e650-46ac-bb91-d998d438f8be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 47ms/step - accuracy: 0.7370 - loss: 0.7559 - val_accuracy: 0.8418 - val_loss: 0.4322\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 45ms/step - accuracy: 0.8681 - loss: 0.3717 - val_accuracy: 0.8688 - val_loss: 0.3583\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 46ms/step - accuracy: 0.8851 - loss: 0.3211 - val_accuracy: 0.8839 - val_loss: 0.3247\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 45ms/step - accuracy: 0.8934 - loss: 0.2961 - val_accuracy: 0.8927 - val_loss: 0.3013\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 46ms/step - accuracy: 0.9030 - loss: 0.2647 - val_accuracy: 0.8891 - val_loss: 0.3047\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.9085 - loss: 0.2510 - val_accuracy: 0.8979 - val_loss: 0.2830\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.9152 - loss: 0.2335 - val_accuracy: 0.8947 - val_loss: 0.2945\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.9207 - loss: 0.2178 - val_accuracy: 0.9042 - val_loss: 0.2694\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 45ms/step - accuracy: 0.9230 - loss: 0.2071 - val_accuracy: 0.8928 - val_loss: 0.2897\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 46ms/step - accuracy: 0.9283 - loss: 0.1995 - val_accuracy: 0.9037 - val_loss: 0.2765\n",
            "Test Accuracy without First Dense Layer: 0.9037\n",
            "Training Time without First Dense Layer: 742.69 seconds\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 190ms/step - accuracy: 0.7836 - loss: 0.5914 - val_accuracy: 0.8684 - val_loss: 0.3600\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 190ms/step - accuracy: 0.8937 - loss: 0.2861 - val_accuracy: 0.8960 - val_loss: 0.2835\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 190ms/step - accuracy: 0.9116 - loss: 0.2377 - val_accuracy: 0.9074 - val_loss: 0.2582\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 189ms/step - accuracy: 0.9278 - loss: 0.1927 - val_accuracy: 0.9106 - val_loss: 0.2531\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 193ms/step - accuracy: 0.9377 - loss: 0.1645 - val_accuracy: 0.9111 - val_loss: 0.2565\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 187ms/step - accuracy: 0.9500 - loss: 0.1332 - val_accuracy: 0.9156 - val_loss: 0.2603\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 187ms/step - accuracy: 0.9580 - loss: 0.1119 - val_accuracy: 0.9113 - val_loss: 0.2815\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - accuracy: 0.9649 - loss: 0.0932 - val_accuracy: 0.9123 - val_loss: 0.2787\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 190ms/step - accuracy: 0.9716 - loss: 0.0751 - val_accuracy: 0.9074 - val_loss: 0.3329\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 194ms/step - accuracy: 0.9756 - loss: 0.0629 - val_accuracy: 0.9155 - val_loss: 0.3406\n",
            "Test Accuracy with Dense(4096): 0.9155\n",
            "Training Time with Dense(4096): 1973.90 seconds\n",
            "\n",
            "Summary of CNN Model Modifications:\n",
            "Model                         Test Accuracy  Training Time (s)\n",
            "------------------------------------------------------------\n",
            "Original CNN (Fashion-MNIST)  91.39%         787.45         \n",
            "CNN Without First Dense       0.9037         742.69\n",
            "CNN with Dense(4096)          0.9155         1973.90\n",
            "\n",
            " Observations:\n",
            "- Taking out the first Dense layer makes training faster but lowers accuracy.\n",
            "- Adding a Dense(4096) layer improves accuracy a little but makes training slower.\n",
            "- If your computer is slow, using a smaller Dense layer (512 or 1024 neurons) is a better choice.\n"
          ]
        }
      ]
    }
  ]
}